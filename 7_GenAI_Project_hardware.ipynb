{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 1. SETUP: Install necessary libraries and configure the API key\n",
        "# ==============================================================================\n",
        "# This cell installs all the required packages for LangChain, Gemini, and ChromaDB.\n",
        "!pip install -q -U google-generativeai langchain langchain-community langchain-core langchain-google-genai chromadb langgraph\n",
        "\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import textwrap\n",
        "from IPython.display import display, Markdown"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoJHJn4MKzT1",
        "outputId": "f8f8149c-41ed-4ac2-aaa2-98f4b55ce1db"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m152.4/152.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.0/50.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Configure your API key ---\n",
        "# For security, it's best to use Colab's \"Secrets\" feature (key icon on the left)\n",
        "# to store your API key. Name the secret \"GEMINI_API_KEY\".\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    GEMINI_API_KEY = \"AIzaSyBS_Y8itRDLdBZx54-iRLbXS07sIbJIW4M\"\n",
        "    genai.configure(api_key=GEMINI_API_KEY)\n",
        "    print(\"‚úÖ Gemini API key configured successfully from Colab Secrets.\")\n",
        "except (ImportError, userdata.SecretNotFoundError):\n",
        "    print(\"‚ö†Ô∏è Could not find GEMINI_API_KEY in Colab Secrets. Checking environment variables.\")\n",
        "    try:\n",
        "        GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY')\n",
        "        if not GEMINI_API_KEY:\n",
        "            raise ValueError(\"GEMINI_API_KEY not found in environment variables.\")\n",
        "        genai.configure(api_key=GEMINI_API_KEY)\n",
        "        print(\"‚úÖ Gemini API key configured successfully from environment variables.\")\n",
        "    except (ValueError, TypeError):\n",
        "        print(\"üî¥ Gemini API key not found. The simulation will run, but analysis will be disabled.\")\n",
        "        GEMINI_API_KEY = None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TjkcmegK4AW",
        "outputId": "bb680419-bec9-4809-e2c9-974baf3281af"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Gemini API key configured successfully from Colab Secrets.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 2. USE CASE: PREDICTIVE MAINTENANCE FOR A WIND TURBINE FARM\n",
        "#\n",
        "# We are building an AI advisor that monitors a Vestas V112 wind turbine.\n",
        "# It uses a knowledge base of maintenance manuals and incident reports to\n",
        "# provide intelligent analysis when anomalies are detected.\n",
        "# =============================================================================="
      ],
      "metadata": {
        "id": "JUIlWFl_K6Gk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 3. KNOWLEDGE BASE & VECTOR DATABASE SETUP\n",
        "#\n",
        "# Here, we define our documents and load them into a ChromaDB vector store.\n",
        "# This process involves:\n",
        "#   1. Defining the raw text documents (manuals, reports, etc.).\n",
        "#   2. Splitting the documents into smaller, manageable chunks.\n",
        "#   3. Using a Gemini embedding model to convert the text chunks into vectors.\n",
        "#   4. Storing these vectors in ChromaDB for efficient semantic search.\n",
        "# =============================================================================="
      ],
      "metadata": {
        "id": "nuXsq0qEK9O1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import LangChain components\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.docstore.document import Document\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "# --- Expanded Knowledge Base for the Wind Turbine ---\n",
        "DOCUMENTS = [\n",
        "    \"MAINTENANCE MANUAL: Vestas V112 Gearbox. Section 5.1: Temperature Monitoring. Normal operating temperature for the primary gearbox bearing is between 60¬∞C and 85¬∞C. Temperatures exceeding 95¬∞C are considered critical and trigger an automatic lubrication cycle. If the temperature remains above 95¬∞C for more than 10 minutes, a controlled shutdown is recommended to prevent oil degradation and component wear. Common causes for overheating include low oil levels, coolant pump failure, or excessive friction from worn bearings.\",\n",
        "    \"TECHNICAL SPECIFICATIONS: Vestas V112. Rotor Speed: Normal operating range is 12-20 RPM. Speeds exceeding 22 RPM are outside of the standard operational envelope and may indicate a fault in the pitch control system or extreme wind conditions. The system is designed to automatically pitch the blades to feather in high winds and control the rotor speed. A failure in this system can lead to dangerous overspeed conditions.\",\n",
        "    \"DIAGNOSTICS GUIDE: Vibration Analysis. Section 3.2: High-Frequency Vibrations. Vibrations in the 2-5 g range on the nacelle main housing typically indicate a developing gear tooth fault or a significant bearing imbalance. These vibrations can propagate through the structure, causing cascading failures. Immediate action required: Correlate vibration data with acoustic sensor data if available. Plan for a borescope inspection of the gearbox within the next 48 operational hours.\",\n",
        "    \"INCIDENT REPORT: WTG-07 (West Field) - 2023-08-15. Root Cause Analysis: Catastrophic gearbox failure. Initial event was a sustained period of high vibration (avg. 4.5 g) ignored for 72 hours. Subsequent oil analysis showed high particulate count, indicating severe wear. The failure was preceded by a gradual increase in gearbox temperature over a 2-week period. Recommendation: High-g vibration alerts must be treated as critical and require immediate investigation, regardless of other sensor readings being normal.\",\n",
        "    \"SYSTEM MANUAL: Blade Pitch Control. The hydraulic pitch system maintains optimal blade angle for power generation and speed regulation. Normal hydraulic pressure is 180-220 bar. Low pressure (below 170 bar) can lead to sluggish pitch response, causing rotor overspeed in gusting winds. High pressure (above 230 bar) indicates a blockage or a faulty accumulator and risks damaging hydraulic seals.\"\n",
        "]\n",
        "\n",
        "print(\"\\nSetting up Vector Database...\")\n",
        "docs = [Document(page_content=text) for text in DOCUMENTS]\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "chunked_docs = text_splitter.split_documents(docs)\n",
        "print(f\"Knowledge base split into {len(chunked_docs)} chunks.\")\n",
        "\n",
        "retriever = None\n",
        "if GEMINI_API_KEY:\n",
        "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=GEMINI_API_KEY)\n",
        "    vector_store = Chroma.from_documents(chunked_docs, embeddings)\n",
        "    retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
        "    print(\"‚úÖ Vector store and retriever created successfully.\")\n",
        "else:\n",
        "    print(\"üî¥ Vector store creation skipped due to missing API key.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvPLSz92LBI1",
        "outputId": "ba4fbea5-4fd5-434c-ccb6-1fddf7c6ade8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Setting up Vector Database...\n",
            "Knowledge base split into 5 chunks.\n",
            "‚úÖ Vector store and retriever created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 4. SIMULATION & AGENT TOOLS\n",
        "#\n",
        "# We define the Sensor and a new Advisor class that holds the sensors.\n",
        "# Then, we create \"tools\" that the LangGraph agent can use to interact\n",
        "# with its environment (i.e., the knowledge base and the live sensor data).\n",
        "# ==============================================================================\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "class Sensor:\n",
        "    \"\"\"Represents a single IoT sensor (reused from previous version).\"\"\"\n",
        "    def __init__(self, id, name, unit, normal_min, normal_max, anomaly_chance=0.1):\n",
        "        self.id = id\n",
        "        self.name = name\n",
        "        self.unit = unit\n",
        "        self.normal_min = normal_min\n",
        "        self.normal_max = normal_max\n",
        "        self.anomaly_chance = anomaly_chance\n",
        "        self.current_value = 0\n",
        "        self.is_anomaly = False\n",
        "        self.update_value()\n",
        "\n",
        "    def update_value(self):\n",
        "        \"\"\"Simulates a new sensor reading.\"\"\"\n",
        "        if random.random() < self.anomaly_chance:\n",
        "            # Generate a more realistic anomaly\n",
        "            self.current_value = self.normal_max * (1 + random.uniform(0.15, 0.4))\n",
        "            self.is_anomaly = True\n",
        "        else:\n",
        "            range_width = self.normal_max - self.normal_min\n",
        "            self.current_value = self.normal_min + (random.random() * range_width)\n",
        "            self.is_anomaly = False\n",
        "        return self.current_value, self.is_anomaly\n",
        "\n",
        "class MaintenanceAdvisor:\n",
        "    \"\"\"Manages sensors and provides their status to the agent.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.sensors = {}\n",
        "\n",
        "    def add_sensor(self, **kwargs):\n",
        "        sensor = Sensor(**kwargs)\n",
        "        self.sensors[sensor.id] = sensor\n",
        "\n",
        "    def check_all_sensors(self):\n",
        "        \"\"\"Updates and prints the status of all sensors, returning anomalies.\"\"\"\n",
        "        print(\"-\" * 70)\n",
        "        print(f\"Time: {time.strftime('%Y-%m-%d %H:%M:%S')} | Monitoring Wind Turbine WTG-04\")\n",
        "        print(\"-\" * 70)\n",
        "        anomalies_found = []\n",
        "        for sensor in self.sensors.values():\n",
        "            value, is_anomaly = sensor.update_value()\n",
        "            status_msg = \"!! ANOMALY !!\" if is_anomaly else \"Normal\"\n",
        "            color_start = \"\\033[91m\" if is_anomaly else \"\\033[92m\"\n",
        "            color_end = \"\\033[0m\"\n",
        "            print(f\"  Sensor: {sensor.name:<25} | Value: {value:>7.2f} {sensor.unit:<5} | Status: {color_start}{status_msg}{color_end}\")\n",
        "            if is_anomaly:\n",
        "                anomalies_found.append(sensor)\n",
        "        print(\"-\" * 70 + \"\\n\")\n",
        "        return anomalies_found\n",
        "\n",
        "    def get_formatted_sensor_status(self) -> str:\n",
        "        \"\"\"Returns a string summary of all current sensor readings.\"\"\"\n",
        "        status_lines = [\"Current Live Sensor Readings for WTG-04:\"]\n",
        "        for sensor in self.sensors.values():\n",
        "            status_lines.append(f\"- {sensor.name}: {sensor.current_value:.2f} {sensor.unit}\")\n",
        "        return \"\\n\".join(status_lines)"
      ],
      "metadata": {
        "id": "4t8ATH6nLjmq"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Define Agent Tools ---\n",
        "# The agent will decide which of these functions to call based on the user's question.\n",
        "\n",
        "@tool\n",
        "def retrieve_knowledge_base(query: str) -> str:\n",
        "    \"\"\"\n",
        "    Searches the wind turbine maintenance knowledge base (manuals, incident reports)\n",
        "    to find information relevant to a specific problem or question.\n",
        "    \"\"\"\n",
        "    print(f\"--- TOOL: Searching knowledge base for: '{query}' ---\")\n",
        "    if not retriever:\n",
        "        return \"Knowledge base is not available.\"\n",
        "    docs = retriever.invoke(query)\n",
        "    return \"\\n\\n---\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "# Instantiate the advisor globally so the tool can access it\n",
        "advisor = MaintenanceAdvisor()\n",
        "\n",
        "@tool\n",
        "def get_current_sensor_status() -> str:\n",
        "    \"\"\"\n",
        "    Gets the current real-time status of all physical wind turbine sensors.\n",
        "    Use this to check if other systems are also showing abnormal readings.\n",
        "    \"\"\"\n",
        "    print(\"--- TOOL: Reading live sensor data ---\")\n",
        "    return advisor.get_formatted_sensor_status()\n"
      ],
      "metadata": {
        "id": "aM4gA128LuBR"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 5. LANGGRAPH AGENT: Building the Interactive Bot\n",
        "#\n",
        "# Here we define the structure and logic of our agent using LangGraph.\n",
        "# The graph defines how the agent thinks:\n",
        "#   1. Agent: The LLM decides to either answer the user, or use a tool.\n",
        "#   2. Tool Node: If a tool is chosen, this node executes it.\n",
        "#   3. The result is fed back to the agent to generate a final response.\n",
        "# ==============================================================================\n",
        "\n",
        "from typing import TypedDict, Annotated, List\n",
        "import operator\n",
        "from langchain_core.messages import BaseMessage, HumanMessage, ToolMessage, AIMessage\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "graph_app = None\n",
        "\n",
        "if GEMINI_API_KEY:\n",
        "    print(\"\\nBuilding LangGraph Agent...\")\n",
        "    # The agent's state is the memory of the conversation.\n",
        "    # `operator.add` ensures messages are appended to the list, not overwritten.\n",
        "    class AgentState(TypedDict):\n",
        "        messages: Annotated[List[BaseMessage], operator.add]\n",
        "\n",
        "    # Initialize the LLM and bind the tools to it\n",
        "    llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0.2,google_api_key=GEMINI_API_KEY)\n",
        "    tools = [retrieve_knowledge_base, get_current_sensor_status]\n",
        "    llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "    # Agent node: calls the LLM to decide the next action\n",
        "    def agent_node(state: AgentState):\n",
        "        response = llm_with_tools.invoke(state['messages'])\n",
        "        return {\"messages\": [response]}\n",
        "\n",
        "    # Tool node: executes the chosen tool\n",
        "    tool_node = ToolNode(tools)\n",
        "\n",
        "    # Conditional routing: checks if the LLM's response was a tool call or a final answer\n",
        "    def should_continue(state: AgentState) -> str:\n",
        "        \"\"\"\n",
        "        Determines the next step in the graph.\n",
        "\n",
        "        If the last message from the agent contains tool calls, route to the 'tools' node.\n",
        "        Otherwise, the agent has finished its turn, so end the process.\n",
        "        \"\"\"\n",
        "        last_message = state['messages'][-1]\n",
        "        # If the LLM returned tool calls, we must execute them.\n",
        "        if last_message.tool_calls:\n",
        "            return \"tools\"\n",
        "        # Otherwise, the agent has given a final answer, so we end the turn.\n",
        "        return \"end\"\n",
        "\n",
        "    # Define the graph structure\n",
        "    workflow = StateGraph(AgentState)\n",
        "    workflow.add_node(\"agent\", agent_node)\n",
        "    workflow.add_node(\"tools\", tool_node)\n",
        "\n",
        "    # Set the entry point and the edges\n",
        "    workflow.set_entry_point(\"agent\")\n",
        "    workflow.add_conditional_edges(\n",
        "        \"agent\",\n",
        "        should_continue,\n",
        "        {\"tools\": \"tools\", \"end\": END}\n",
        "    )\n",
        "    workflow.add_edge(\"tools\", \"agent\")\n",
        "\n",
        "    # The checkpointer allows the graph to remember conversation history\n",
        "    memory = MemorySaver()\n",
        "    graph_app = workflow.compile(checkpointer=memory)\n",
        "    print(\"‚úÖ LangGraph Agent built successfully.\")\n",
        "else:\n",
        "    print(\"üî¥ LangGraph agent creation skipped.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiBqzummL0dG",
        "outputId": "66c055d6-9ff1-4fc8-8479-62366fa3c83e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Building LangGraph Agent...\n",
            "‚úÖ LangGraph Agent built successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 6. RUN INTERACTIVE SIMULATION\n",
        "# ==============================================================================\n",
        "print(\"\\nüöÄ Starting Wind Turbine Maintenance Advisor Simulation...\")\n",
        "\n",
        "# Add sensors to the advisor instance\n",
        "advisor.add_sensor(id='temp-gearbox-01', name='Gearbox Bearing Temp', unit='¬∞C', normal_min=60, normal_max=85, anomaly_chance=0.2)\n",
        "advisor.add_sensor(id='speed-rotor-01', name='Rotor Speed', unit='RPM', normal_min=12, normal_max=20, anomaly_chance=0.1)\n",
        "advisor.add_sensor(id='vibe-nacelle-01', name='Nacelle Vibration', unit='g', normal_min=0.2, normal_max=1.8, anomaly_chance=0.15)\n",
        "advisor.add_sensor(id='pressure-hyd-01', name='Pitch Hydraulic Pressure', unit='bar', normal_min=180, normal_max=220, anomaly_chance=0.1)\n",
        "\n",
        "# --- Main Simulation Loop ---\n",
        "simulation_cycles = 10\n",
        "try:\n",
        "    for i in range(simulation_cycles):\n",
        "        if not GEMINI_API_KEY:\n",
        "            print(\"Simulation running in offline mode. AI analysis is disabled.\")\n",
        "            advisor.check_all_sensors()\n",
        "            time.sleep(4)\n",
        "            continue\n",
        "\n",
        "        anomalies = advisor.check_all_sensors()\n",
        "\n",
        "        if anomalies:\n",
        "            anomaly = anomalies[0] # Focus on the first detected anomaly\n",
        "            print(f\"üö® ANOMALY DETECTED! Initializing Maintenance Advisor Bot for '{anomaly.name}'.\\n\")\n",
        "\n",
        "            # --- Start Interactive Chat Session ---\n",
        "            # A unique ID for the conversation thread\n",
        "            config = {\"configurable\": {\"thread_id\": f\"thread-{int(time.time())}\"}}\n",
        "\n",
        "            # Formulate the initial problem statement for the agent\n",
        "            initial_prompt = (\n",
        "                \"You are an expert AI predictive maintenance advisor for Vestas V112 wind turbines. \"\n",
        "                \"An urgent anomaly has been detected on turbine WTG-04. \"\n",
        "                f\"The '{anomaly.name}' sensor is reading an abnormal value of {anomaly.current_value:.2f} {anomaly.unit}. \"\n",
        "                \"Please perform an initial analysis. Use your tools to search the knowledge base for causes and recommended actions. \"\n",
        "                \"Provide a clear, actionable summary in Markdown format.\"\n",
        "            )\n",
        "\n",
        "           # Invoke the graph to get the initial analysis\n",
        "            events = graph_app.stream({\"messages\": [HumanMessage(content=initial_prompt)]}, config)\n",
        "            for event in events:\n",
        "                for v in event.values():\n",
        "                    # CORRECTED LOGIC:\n",
        "                    # Only print the final response from the agent (which is an AIMessage without tool_calls).\n",
        "                    # This avoids trying to access .tool_calls on a ToolMessage.\n",
        "                    if \"messages\" in v:\n",
        "                        last_message = v[\"messages\"][-1]\n",
        "                        if isinstance(last_message, AIMessage) and not last_message.tool_calls:\n",
        "                            print(\"\\nü§ñ Advisor:\")\n",
        "                            display(Markdown(last_message.content))\n",
        "\n",
        "            # --- Enter interactive Q&A loop ---\n",
        "            while True:\n",
        "                user_input = input(\"\\n\\033[93mAsk a follow-up question (or type 'continue' to resume monitoring, 'exit' to stop): \\033[0m\")\n",
        "                if user_input.lower() == 'exit':\n",
        "                    raise KeyboardInterrupt # Exit the entire simulation\n",
        "                if user_input.lower() == 'continue':\n",
        "                    print(\"\\n‚úÖ Resuming automated monitoring...\")\n",
        "                    break # Exit the Q&A loop and continue the simulation\n",
        "\n",
        "                # Send the user's question to the agent\n",
        "                events = graph_app.stream({\"messages\": [HumanMessage(content=user_input)]}, config)\n",
        "                for event in events:\n",
        "                    for v in event.values():\n",
        "                        # APPLY THE SAME CORRECTED LOGIC HERE:\n",
        "                        if \"messages\" in v:\n",
        "                            last_message = v[\"messages\"][-1]\n",
        "                            if isinstance(last_message, AIMessage) and not last_message.tool_calls:\n",
        "                                print(\"\\nü§ñ Advisor:\")\n",
        "                                display(Markdown(last_message.content))\n",
        "\n",
        "\n",
        "        # Wait before the next cycle\n",
        "        time.sleep(5)\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\nSimulation stopped by user.\")\n",
        "finally:\n",
        "    print(\"\\n‚úÖ Simulation complete.\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üöÄ Starting Wind Turbine Maintenance Advisor Simulation...\n",
            "----------------------------------------------------------------------\n",
            "Time: 2025-06-13 21:53:01 | Monitoring Wind Turbine WTG-04\n",
            "----------------------------------------------------------------------\n",
            "  Sensor: Gearbox Bearing Temp      | Value:   64.71 ¬∞C    | Status: \u001b[92mNormal\u001b[0m\n",
            "  Sensor: Rotor Speed               | Value:   16.73 RPM   | Status: \u001b[92mNormal\u001b[0m\n",
            "  Sensor: Nacelle Vibration         | Value:    0.30 g     | Status: \u001b[92mNormal\u001b[0m\n",
            "  Sensor: Pitch Hydraulic Pressure  | Value:  207.63 bar   | Status: \u001b[92mNormal\u001b[0m\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Time: 2025-06-13 21:53:06 | Monitoring Wind Turbine WTG-04\n",
            "----------------------------------------------------------------------\n",
            "  Sensor: Gearbox Bearing Temp      | Value:  114.11 ¬∞C    | Status: \u001b[91m!! ANOMALY !!\u001b[0m\n",
            "  Sensor: Rotor Speed               | Value:   18.07 RPM   | Status: \u001b[92mNormal\u001b[0m\n",
            "  Sensor: Nacelle Vibration         | Value:    1.43 g     | Status: \u001b[92mNormal\u001b[0m\n",
            "  Sensor: Pitch Hydraulic Pressure  | Value:  296.26 bar   | Status: \u001b[91m!! ANOMALY !!\u001b[0m\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "üö® ANOMALY DETECTED! Initializing Maintenance Advisor Bot for 'Gearbox Bearing Temp'.\n",
            "\n",
            "--- TOOL: Searching knowledge base for: 'Gearbox Bearing Temp high' ---\n",
            "--- TOOL: Reading live sensor data ---\n",
            "\n",
            "ü§ñ Advisor:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## URGENT: WTG-04 Gearbox Bearing Over Temperature - Initial Analysis\n\n**Anomaly:** Gearbox Bearing Temp sensor reading 114.11 ¬∞C, exceeding critical threshold (95¬∞C).\n\n**Knowledge Base Findings:**\n\n*   **Normal Operating Temperature:** 60¬∞C - 85¬∞C.\n*   **Critical Temperature:** Above 95¬∞C triggers lubrication cycle; sustained temperature requires controlled shutdown.\n*   **Common Causes:** Low oil levels, coolant pump failure, excessive friction from worn bearings.\n*   **Incident Report (WTG-07):** Gradual temperature increase, high vibration ignored, leading to catastrophic failure.\n\n**Current Sensor Status (WTG-04):**\n\n*   Gearbox Bearing Temp: 114.11 ¬∞C\n*   Rotor Speed: 18.07 RPM\n*   Nacelle Vibration: 1.43 g\n*   Pitch Hydraulic Pressure: 296.26 bar\n\n**Initial Assessment:**\n\nThe gearbox bearing temperature is critically high. Based on the knowledge base and the WTG-07 incident report, this requires immediate attention. While vibration is currently within normal limits (1.43 g), the high temperature is the primary concern.\n\n**Recommended Actions:**\n\n1.  **Initiate Controlled Shutdown:** Immediately initiate a controlled shutdown of WTG-04 to prevent potential oil degradation and component wear.\n2.  **Check Oil Levels:** Verify gearbox oil levels.\n3.  **Inspect Coolant Pump:** Check the coolant pump for proper function.\n4.  **Oil Analysis:** Schedule an immediate oil analysis to check for particulate matter, indicating bearing wear.\n5.  **Escalate for Inspection:** Escalate this issue to on-site maintenance personnel for physical inspection of the gearbox and associated systems."
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 991
        },
        "id": "YA_6TaZ4Kvy0",
        "outputId": "58c498de-3981-4159-ec9a-93ea0689c066"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GmeD6Ro9MXbi"
      },
      "execution_count": 22,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}